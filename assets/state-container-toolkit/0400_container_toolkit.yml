apiVersion: apps/v1
kind: DaemonSet
metadata:
  labels:
    app: nvidia-container-toolkit-daemonset
  name: nvidia-container-toolkit-daemonset
  namespace: gpu-operator-resources
  annotations:
    openshift.io/scc: hostmount-anyuid
spec:
  selector:
    matchLabels:
      app: nvidia-container-toolkit-daemonset
  template:
    metadata:
      # Mark this pod as a critical add-on; when enabled, the critical add-on scheduler
      # reserves resources for critical add-on pods so that they can be rescheduled after
      # a failure.  This annotation works in tandem with the toleration below.
      annotations:
        scheduler.alpha.kubernetes.io/critical-pod: ""
      labels:
        app: nvidia-container-toolkit-daemonset
    spec:
      tolerations:
      # Allow this pod to be rescheduled while the node is in "critical add-ons only" mode.
      # This, along with the annotation above marks this pod as a critical add-on.
      - key: CriticalAddonsOnly
        operator: Exists
      - key: nvidia.com/gpu
        operator: Exists
        effect: NoSchedule
      serviceAccount: nvidia-container-toolkit
      hostPID: true
      containers:
      - image: "FILLED_BY_THE_OPERATOR"
        args: ["/usr/local/nvidia"]
        env:
        - name: RUNTIME_ARGS
          value: ""
        imagePullPolicy: IfNotPresent
        name: nvidia-container-toolkit-ctr
        lifecycle:
          postStart:
            exec:
              command:
              - bash
              - /mnt/probes/startup-hook.sh
        readinessProbe:
          exec:
            command:
              - bash
              - /mnt/probes/ready-probe.sh
            initialDelaySeconds: 5
            periodSeconds: 5
        securityContext:
          privileged: true
          seLinuxOptions:
            level: "s0"
        volumeMounts:
          - name: docker-socket
            mountPath: /var/run/docker.sock
          - name: nvidia-install-path
            mountPath: /run/nvidia
            mountPropagation: Bidirectional
          - name: docker-config
            mountPath: /etc/docker
          - name: nvidia-local
            mountPath: /usr/local/nvidia
          - name: crio-hooks
            mountPath: /usr/share/containers/oci/hooks.d
          - name: probes
            mountPath: /mnt/probes
      volumes:
        - name: docker-socket
          hostPath:
            path: /var/run/docker.sock
        - name: nvidia-install-path
          hostPath:
            path: /run/nvidia
        - name: docker-config
          hostPath:
            path: /etc/docker
        - name: nvidia-local
          hostPath:
            path: /usr/local/nvidia
        - name: crio-hooks
          hostPath:
            path: /etc/containers/oci/hooks.d
        - name: probes
          configMap:
            name: nvidia-container-toolkit
            items:
            - key: startup-hook.sh
              path: startup-hook.sh
            - key: ready-probe.sh
              path: ready-probe.sh
      nodeSelector:
        nvidia.com/gpu.present: "true"
